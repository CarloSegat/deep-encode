{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import random \n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def print_data_summary(data):\n",
    "    print(\"There are {0} datapoints\".format(len(data)))\n",
    "    print(\"There are {0} columns\".format(len(data.columns)))\n",
    "    try:\n",
    "        print(\"There are {0} diffenret movies\".format(len(set(data['s_video_id']))))\n",
    "    except:\n",
    "        pass\n",
    "    # print(data.describe())\n",
    "    \n",
    "def encode_one_hot(data):\n",
    "    categorical_columns = get_categorical_columns(data)\n",
    "    oneHotEncodedData = pd.get_dummies(data, columns=categorical_columns)\n",
    "    \n",
    "    # Test\n",
    "    newNumberOfColumns = len(oneHotEncodedData.columns) \n",
    "\n",
    "    totalDifferentValues = 0\n",
    "    for c in categorical_columns:\n",
    "        totalDifferentValues += len(data[c].unique())\n",
    "\n",
    "    # One hot encoding removes each categorical columns (- len(nonNumericalList)) \n",
    "    # and adds n columns where n is number of different values taken by column (+ totalDifferentValues)\n",
    "    assert len(data.columns) + totalDifferentValues - len(categorical_columns) == newNumberOfColumns\n",
    "    \n",
    "    return oneHotEncodedData\n",
    "\n",
    "def split_train_test(data, test_mask):\n",
    "    # split between train and test\n",
    "    train_mask = list(map(lambda b: not b, test_mask))\n",
    "\n",
    "    train = data[train_mask]\n",
    "    test = data[test_mask]\n",
    "\n",
    "    assert len(train) + len(test) == len(data) \n",
    "\n",
    "    y_train = train.loc[:, ['t_average_vmaf']]\n",
    "    x_train = train.drop(['t_average_vmaf'], axis=1)\n",
    "    assert type(x_train) == type(y_train) \n",
    "\n",
    "    y_test = test.loc[:, ['t_average_vmaf']]\n",
    "    x_test = test.drop(['t_average_vmaf'], axis=1)\n",
    "    assert type(x_test) == type(y_test)\n",
    "\n",
    "    assert len(x_train) == len(y_train)\n",
    "    assert len(x_train.columns) + len(y_train.columns) == len(data.columns)\n",
    "    assert len(x_test) == len(y_test)\n",
    "    assert len(x_test.columns) + len(y_test.columns) == len(data.columns)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def calculate_rmse(y_true, y_predictions):\n",
    "    mse = mean_squared_error(y_true, y_predictions)\n",
    "    rmse = math.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "def calculate_std(y_true, y_predictions):\n",
    "    '''\n",
    "    Standard deviation is calculated considering the absoulte values of the residuals as the\n",
    "    values and the RMSE as the mean.\n",
    "    '''\n",
    "    rmse = calculate_rmse(y_true, y_predictions)\n",
    "    \n",
    "    abs_residuals = np.absolute(y_true - y_predictions)\n",
    "    \n",
    "    \n",
    "    #print(abs_residuals)\n",
    "    #print(abs_residuals.tolist().sort(reverse=True))\n",
    "    tbp = list(np.ravel(abs_residuals))\n",
    "    tbp.sort(reverse=True)\n",
    "    print(\"Printing the 4th quartile to doublecheck std: \")\n",
    "    print(np.percentile(tbp, 75))  # Q3\n",
    "    #print(tbp[0:20])\n",
    "\n",
    "    \n",
    "    rmse_column = np.array([rmse]*len(abs_residuals)).reshape(len(abs_residuals), 1)\n",
    "\n",
    "    #print(\"len(abs_residuals)\")\n",
    "    #print(len(abs_residuals))\n",
    "    #print(\"rmse_column\")\n",
    "    #print(rmse_column)\n",
    "    variance = np.sum(np.square(abs_residuals - rmse_column)) / len(abs_residuals)\n",
    "    std = math.sqrt(variance)\n",
    "    return std\n",
    "\n",
    "def run_model(regression_model, x_train, y_train, x_test, y_test):\n",
    "    '''\n",
    "    Given a sklearn model and the train / test data,\n",
    "    returns the rmse, std and r squared scores of the model\n",
    "    also returns training time in seconds\n",
    "    '''\n",
    "    start_time = datetime.now().timestamp()\n",
    "   \n",
    "    regular_regression = regression_model.fit(x_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "    end_time = datetime.now().timestamp()\n",
    "   \n",
    "    predictions = regression_model.predict(x_test.to_numpy())\n",
    "\n",
    "    rmse = calculate_rmse(y_test.to_numpy(), predictions)\n",
    "\n",
    "    std = calculate_std(y_test.to_numpy(), predictions)\n",
    "\n",
    "    coefficient_of_determination = regression_model.score(x_test.to_numpy(), y_test.to_numpy())\n",
    "    \n",
    "    return Model_results(rmse, std, coefficient_of_determination, end_time - start_time, regression_model)\n",
    "\n",
    "def analyse_model(regression_model, x_train, y_train, x_test, y_test):\n",
    "    regular_regression = regression_model.fit(x_train.to_numpy(), y_train.to_numpy())\n",
    "    \n",
    "    paramRelevance = {'Parameter':x_train.columns.to_list()[:],\n",
    "            'Weight':regular_regression.coef_.tolist()[0]}\n",
    " \n",
    "    dfParam = pd.DataFrame(paramRelevance)\n",
    "\n",
    "    print(dfParam.sort_values(by='Weight', ascending=False)[:])\n",
    "\n",
    "class Model_results:\n",
    "    def __init__(self, rmse, std, cod, time, model):\n",
    "        self.rmse = rmse\n",
    "        self.std = std\n",
    "        self.cod = cod\n",
    "        self.time = time\n",
    "        self.model = model\n",
    "        \n",
    "    def __str__(self):\n",
    "        attrs = vars(self)\n",
    "        return ', '.join(\"%s: %s\" % item for item in attrs.items())\n",
    "    \n",
    "def get_numerical_columns(data):\n",
    "    numerical = data.select_dtypes(exclude=['object'])\n",
    "    exclude_categorical = [col for col in numerical.columns \\\n",
    "                                   if not 'content_category' in col \\\n",
    "                                   and not 'scan_type' in col \\\n",
    "                                   and not 'codec_profile' in col \\\n",
    "                                   and not 's_video_id' in col]\n",
    "    return exclude_categorical\n",
    "\n",
    "def get_categorical_columns(data):\n",
    "    numerical_columns = set(get_numerical_columns(data))\n",
    "    return set(data.columns) - numerical_columns\n",
    "\n",
    "def explore_categorical_features(data):\n",
    "    # explorig categorical columns\n",
    "    nonNumericalFrame = data.select_dtypes(include=['object']).copy()\n",
    "    nonNumericalList = nonNumericalFrame.columns.tolist()\n",
    "    totalDifferentValues = 0\n",
    "    for c in nonNumericalList:\n",
    "        print(\"{0} is non-numerical and values are: {1}\".format(c, nonNumericalFrame[c].unique()))\n",
    "        totalDifferentValues += len(nonNumericalFrame[c].unique())\n",
    "\n",
    "    print(\"There are {0} total possible values among the categorical columns\".format(totalDifferentValues))\n",
    "\n",
    "    # content_category is the most problematic column because it has many possible values\n",
    "    # nonNumericalFrame[\"c_content_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "rawColumns = data.columns\n",
    "rawData = deepcopy(data)\n",
    "\n",
    "# test \n",
    "assert len(get_numerical_columns(data)) + len(get_categorical_columns(data)) == len(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following columns have been removed because empty: {'t_average_vmaf_mobile', 't_average_vmaf_4k', 't_average_psnr'}\n",
      "There were 2883 rows deleted because they had less than 43 valorised features\n",
      "Column e_aspect_ratio always has same value: 16:09, removed\n",
      "Column e_pixel_aspect_ratio always has same value: 1:01, removed\n",
      "Column e_codec always has same value: h264, removed\n",
      "Column e_b_frame_int always has same value: 3, removed\n",
      "Column e_ref_frame_count always has same value: 1.0, removed\n",
      "Column e_bit_depth always has same value: 8.0, removed\n",
      "Column e_pixel_fmt always has same value: yuv420p, removed\n",
      "\n",
      "After inital processing\n",
      "There are 12133 datapoints\n",
      "There are 35 columns\n",
      "\n",
      "After scaling\n",
      "There are 12133 datapoints\n",
      "There are 34 columns\n",
      "\n",
      "After 1 hot encoding categorical features\n",
      "There are 12133 datapoints\n",
      "There are 110 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_storage_size</th>\n",
       "      <th>s_duration</th>\n",
       "      <th>c_si</th>\n",
       "      <th>c_ti</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio30</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio60</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio90</th>\n",
       "      <th>c_scene_change_py_thresh30</th>\n",
       "      <th>c_scene_change_py_thresh50</th>\n",
       "      <th>c_colorhistogram_mean_dark</th>\n",
       "      <th>...</th>\n",
       "      <th>e_codec_profile_high</th>\n",
       "      <th>e_codec_profile_main</th>\n",
       "      <th>s_size_1080_1080</th>\n",
       "      <th>s_size_1280_720</th>\n",
       "      <th>s_size_1920_1080</th>\n",
       "      <th>s_size_1920_800</th>\n",
       "      <th>s_size_1920_818</th>\n",
       "      <th>s_size_352_288</th>\n",
       "      <th>s_size_720_486</th>\n",
       "      <th>s_size_720_608</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_storage_size  s_duration      c_si     c_ti  \\\n",
       "0        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "1        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "2        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "3        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "4        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "\n",
       "   c_scene_change_ffmpeg_ratio30  c_scene_change_ffmpeg_ratio60  \\\n",
       "0                      -0.239026                       -0.74125   \n",
       "1                      -0.239026                       -0.74125   \n",
       "2                      -0.239026                       -0.74125   \n",
       "3                      -0.239026                       -0.74125   \n",
       "4                      -0.239026                       -0.74125   \n",
       "\n",
       "   c_scene_change_ffmpeg_ratio90  c_scene_change_py_thresh30  \\\n",
       "0                      -0.512497                   -1.518056   \n",
       "1                      -0.512497                   -1.518056   \n",
       "2                      -0.512497                   -1.518056   \n",
       "3                      -0.512497                   -1.518056   \n",
       "4                      -0.512497                   -1.518056   \n",
       "\n",
       "   c_scene_change_py_thresh50  c_colorhistogram_mean_dark  ...  \\\n",
       "0                   -1.161942                   -0.214322  ...   \n",
       "1                   -1.161942                   -0.214322  ...   \n",
       "2                   -1.161942                   -0.214322  ...   \n",
       "3                   -1.161942                   -0.214322  ...   \n",
       "4                   -1.161942                   -0.214322  ...   \n",
       "\n",
       "   e_codec_profile_high  e_codec_profile_main  s_size_1080_1080  \\\n",
       "0                     1                     0                 0   \n",
       "1                     0                     1                 0   \n",
       "2                     0                     1                 0   \n",
       "3                     0                     1                 0   \n",
       "4                     0                     1                 0   \n",
       "\n",
       "   s_size_1280_720  s_size_1920_1080  s_size_1920_800  s_size_1920_818  \\\n",
       "0                0                 1                0                0   \n",
       "1                0                 1                0                0   \n",
       "2                0                 1                0                0   \n",
       "3                0                 1                0                0   \n",
       "4                0                 1                0                0   \n",
       "\n",
       "   s_size_352_288  s_size_720_486  s_size_720_608  \n",
       "0               0               0               0  \n",
       "1               0               0               0  \n",
       "2               0               0               0  \n",
       "3               0               0               0  \n",
       "4               0               0               0  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPROCESSING\n",
    "\n",
    "# 1 Remove empty columns\n",
    "data = data.dropna(axis=1, thresh=len(data.columns))\n",
    "print(\"The following columns have been removed because empty: {0}\".format(set(rawColumns) - set(data.columns)))\n",
    "\n",
    "# 2 Remove rows with missing values\n",
    "threshold = len(data.columns)\n",
    "data = data.dropna(axis=0, thresh=threshold)\n",
    "print(\"There were {0} rows deleted because they had less than {1} valorised features\".format(len(rawData) - len(data), threshold))\n",
    "\n",
    "# 3 Remove columns that always have the same value\n",
    "nunique = data.apply(pd.Series.nunique)\n",
    "cols_to_drop = nunique[nunique == 1].index\n",
    "data = data.drop(cols_to_drop, axis=1)\n",
    "for c in cols_to_drop.tolist():\n",
    "    print(\"Column {0} always has same value: {1}, removed\".format(c, rawData[c].tolist()[1]))\n",
    "assert len(nunique) == len(data.columns) + len(cols_to_drop)\n",
    "\n",
    "# 4 Remove video id\n",
    "data = data.drop(['s_video_id'], axis = 1)\n",
    "\n",
    "print(\"\\nAfter inital processing\")\n",
    "print_data_summary(data)\n",
    "\n",
    "# 5 Coalesce width and height to a categorical feature\n",
    "# print(data.groupby(['s_width','s_height']).size().reset_index().rename(columns={0:'count'}))\n",
    "\n",
    "data['s_size'] = data.apply(lambda row: str(row['s_width']) + \"_\" + str(row['s_height']), axis=1)\n",
    "data = data.drop(['s_width', 's_height'], axis = 1)\n",
    "\n",
    "# 6 convert size to \n",
    "\n",
    "# explore_categorical_features(data)\n",
    "\n",
    "# 6 Scale data (mean is zero)\n",
    "\n",
    "# split data in numerical, categorical, y columns\n",
    "y = data['t_average_vmaf']\n",
    "categorical = data[get_categorical_columns(data.drop(['t_average_vmaf'], axis = 1))]\n",
    "numerical = data[get_numerical_columns(data.drop(['t_average_vmaf'], axis = 1))]\n",
    "\n",
    "# scale only numerical\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(numerical)\n",
    "scaled_numerical = scaler.transform(numerical)\n",
    "\n",
    "# recombine everything\n",
    "numerical_data = pd.DataFrame(scaled_numerical, numerical.index, columns=numerical.columns)\n",
    "# test\n",
    "assert len(numerical_data.columns) + len(categorical.columns) + 1 == len(data.columns)\n",
    "data = pd.concat([numerical_data, categorical, y], axis=1)\n",
    "\n",
    "print(\"\\nAfter scaling\")\n",
    "print_data_summary(data)\n",
    "\n",
    "# 5 One hot encoding categorical columns\n",
    "\n",
    "# pro wrt label encoding: the model wont derive false relations between columns based on numerical values (2 > 1)\n",
    "# con wrt label encoding: more columns are introduced\n",
    "\n",
    "data = encode_one_hot(data)\n",
    "print(\"\\nAfter 1 hot encoding categorical features\")\n",
    "print_data_summary(data)\n",
    "\n",
    "\n",
    "preprocessed_data = deepcopy(data)\n",
    "\n",
    "preprocessed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original oclumns 37\n",
      "After augmenting the data\n",
      "There are 12133 datapoints\n",
      "There are 850 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_storage_size</th>\n",
       "      <th>s_duration</th>\n",
       "      <th>c_si</th>\n",
       "      <th>c_ti</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio30</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio60</th>\n",
       "      <th>c_scene_change_ffmpeg_ratio90</th>\n",
       "      <th>c_scene_change_py_thresh30</th>\n",
       "      <th>c_scene_change_py_thresh50</th>\n",
       "      <th>c_colorhistogram_mean_dark</th>\n",
       "      <th>...</th>\n",
       "      <th>s_size_1920_818_*_s_size_720_608</th>\n",
       "      <th>s_size_352_288_squared</th>\n",
       "      <th>s_size_352_288cubic</th>\n",
       "      <th>s_size_352_288_*_s_size_720_486</th>\n",
       "      <th>s_size_352_288_*_s_size_720_608</th>\n",
       "      <th>s_size_720_486_squared</th>\n",
       "      <th>s_size_720_486cubic</th>\n",
       "      <th>s_size_720_486_*_s_size_720_608</th>\n",
       "      <th>s_size_720_608_squared</th>\n",
       "      <th>s_size_720_608cubic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.49794</td>\n",
       "      <td>-0.598653</td>\n",
       "      <td>0.653567</td>\n",
       "      <td>-0.41539</td>\n",
       "      <td>-0.239026</td>\n",
       "      <td>-0.74125</td>\n",
       "      <td>-0.512497</td>\n",
       "      <td>-1.518056</td>\n",
       "      <td>-1.161942</td>\n",
       "      <td>-0.214322</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_storage_size  s_duration      c_si     c_ti  \\\n",
       "0        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "1        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "2        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "3        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "4        -0.49794   -0.598653  0.653567 -0.41539   \n",
       "\n",
       "   c_scene_change_ffmpeg_ratio30  c_scene_change_ffmpeg_ratio60  \\\n",
       "0                      -0.239026                       -0.74125   \n",
       "1                      -0.239026                       -0.74125   \n",
       "2                      -0.239026                       -0.74125   \n",
       "3                      -0.239026                       -0.74125   \n",
       "4                      -0.239026                       -0.74125   \n",
       "\n",
       "   c_scene_change_ffmpeg_ratio90  c_scene_change_py_thresh30  \\\n",
       "0                      -0.512497                   -1.518056   \n",
       "1                      -0.512497                   -1.518056   \n",
       "2                      -0.512497                   -1.518056   \n",
       "3                      -0.512497                   -1.518056   \n",
       "4                      -0.512497                   -1.518056   \n",
       "\n",
       "   c_scene_change_py_thresh50  c_colorhistogram_mean_dark  ...  \\\n",
       "0                   -1.161942                   -0.214322  ...   \n",
       "1                   -1.161942                   -0.214322  ...   \n",
       "2                   -1.161942                   -0.214322  ...   \n",
       "3                   -1.161942                   -0.214322  ...   \n",
       "4                   -1.161942                   -0.214322  ...   \n",
       "\n",
       "   s_size_1920_818_*_s_size_720_608  s_size_352_288_squared  \\\n",
       "0                                 0                       0   \n",
       "1                                 0                       0   \n",
       "2                                 0                       0   \n",
       "3                                 0                       0   \n",
       "4                                 0                       0   \n",
       "\n",
       "   s_size_352_288cubic  s_size_352_288_*_s_size_720_486  \\\n",
       "0                    0                                0   \n",
       "1                    0                                0   \n",
       "2                    0                                0   \n",
       "3                    0                                0   \n",
       "4                    0                                0   \n",
       "\n",
       "   s_size_352_288_*_s_size_720_608  s_size_720_486_squared  \\\n",
       "0                                0                       0   \n",
       "1                                0                       0   \n",
       "2                                0                       0   \n",
       "3                                0                       0   \n",
       "4                                0                       0   \n",
       "\n",
       "   s_size_720_486cubic  s_size_720_486_*_s_size_720_608  \\\n",
       "0                    0                                0   \n",
       "1                    0                                0   \n",
       "2                    0                                0   \n",
       "3                    0                                0   \n",
       "4                    0                                0   \n",
       "\n",
       "   s_size_720_608_squared  s_size_720_608cubic  \n",
       "0                       0                    0  \n",
       "1                       0                    0  \n",
       "2                       0                    0  \n",
       "3                       0                    0  \n",
       "4                       0                    0  \n",
       "\n",
       "[5 rows x 850 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data augmentation\n",
    "\n",
    "# from [x, y, z] we want to obtain \n",
    "# [x, y, z, x**2, y**2, z**2, x*y, x*z, y*z]\n",
    "# aka all the degree 2 polinomyals \n",
    "\n",
    "# only consider numerical columns, exluce categorical\n",
    "\n",
    "exclude_categorical = get_numerical_columns(preprocessed_data)\n",
    "\n",
    "theoretical_final_number_of_columns = len(data.columns) + \\\n",
    "+ len(exclude_categorical) + \\\n",
    "((len(exclude_categorical)) * (len(exclude_categorical) - 1)) / 2\n",
    "\n",
    "baseForAugmentation = data[exclude_categorical]\n",
    "\n",
    "columnsCopy = baseForAugmentation.columns.tolist()\n",
    "\n",
    "print(\"original oclumns {0}\".format(len(baseForAugmentation.columns)))\n",
    "\n",
    "for c in baseForAugmentation.columns:\n",
    "\n",
    "    data[c + \"_squared\"] = data[c] ** 2\n",
    "    data[c + \"cubic\"] = data[c] ** 3\n",
    "    \n",
    "    columnsCopy.remove(c)\n",
    "    for cc in columnsCopy:\n",
    "        t = data[c] * data[cc]\n",
    "        data[c + \"_*_\" + cc ] = data[c] * data[cc]\n",
    "\n",
    "# assert(int(theoretical_final_number_of_columns) == len(data.columns.tolist()))\n",
    "\n",
    "print(\"After augmenting the data\")\n",
    "print_data_summary(data)\n",
    "augmented_data = deepcopy(data)\n",
    "augmented_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying PCA to the data\n",
      "There are 12133 datapoints\n",
      "There are 6 columns\n"
     ]
    }
   ],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "import math\n",
    "\n",
    "# for PCA to work well data needs to be scaled (mean is zero)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(augmented_data.drop(['t_average_vmaf'], axis=1))\n",
    "scaledData = scaler.transform(augmented_data.drop(['t_average_vmaf'], axis=1))\n",
    "\n",
    "# reducing the data to an arbitrary number of dimensions\n",
    "pca = PCA(n_components=5)\n",
    "pca.fit(scaledData)\n",
    "pca_data = pca.transform(scaledData)\n",
    "\n",
    "# Principal components are new variables that are constructed \n",
    "# as linear combinations or mixtures of the initial variables.\n",
    "# We don't have the original headers names\n",
    "\n",
    "pca_data = pd.DataFrame(data=pca_data)\n",
    "\n",
    "if not pca_data.index.equals(augmented_data.index):\n",
    "    pca_data.index = augmented_data.index\n",
    "    \n",
    "# adding the y back\n",
    "# it was removed because otherwise it would have been lost in the pca process\n",
    "pca_data['t_average_vmaf'] = augmented_data['t_average_vmaf']\n",
    "\n",
    "print(\"After applying PCA to the data\")\n",
    "print_data_summary(pca_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitthe 3 datasets (preprocessed, augmented, PCAed)\n",
    "# Note the the same splitting is applied across all 3 \n",
    "\n",
    "test_mask = np.random.rand(len(data), 1) > 0.60\n",
    "\n",
    "x_train_pre, y_train_pre, x_test_pre, y_test_pre = split_train_test(preprocessed_data, test_mask)\n",
    "x_train_aug, y_train_aug, x_test_aug, y_test_aug = split_train_test(augmented_data, test_mask)\n",
    "x_train_pca, y_train_pca, x_test_pca, y_test_pca = split_train_test(pca_data, test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Parameter        Weight\n",
      "28         s_scan_type_interlaced  2.364968e+12\n",
      "29        s_scan_type_progressive  2.364968e+12\n",
      "23                       e_height  1.019149e+12\n",
      "26                     e_gop_size  8.588038e+11\n",
      "53    c_content_category_fountain  2.162891e+11\n",
      "..                            ...           ...\n",
      "25                    e_framerate -8.588038e+11\n",
      "22                        e_width -1.019149e+12\n",
      "98        e_scan_type_progressive -1.402630e+12\n",
      "97  e_scan_type_not supported yet -1.402630e+12\n",
      "96         e_scan_type_interlaced -1.402630e+12\n",
      "\n",
      "[109 rows x 2 columns]\n",
      "Regular regression\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "7.65900634765625\n",
      "rmse: 7.285720740834151, std: 4.919918603616527, cod: 0.9453210787162668, time: 0.011597156524658203, model: LinearRegression()\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "1.0551942652980983e-10\n",
      "rmse: 9.594905900137562e-11, std: 6.489149746727142e-11, cod: 1.0, time: 0.22246289253234863, model: LinearRegression()\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "39.6832791317888\n",
      "rmse: 31.141545067262758, std: 15.014849668811944, cod: 0.0010236462142135805, time: 0.002760171890258789, model: LinearRegression()\n",
      "\n",
      "Lasso regression\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "51.77936846619984\n",
      "rmse: 8.812196360172022, std: 2483.184063645355, cod: 0.9200086128342326, time: 0.027510881423950195, model: Lasso(alpha=0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/carlo/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:529: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25749.495583868622, tolerance: 710.747700993931\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the 4th quartile to doublecheck std: \n",
      "56.346526856221914\n",
      "rmse: 1.9430468132929464, std: 2956.0345638116487, cod: 0.99611096882497, time: 2.6351962089538574, model: Lasso(alpha=0.8)\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "39.744292013832236\n",
      "rmse: 31.143723037090805, std: 1046.0497287254518, cod: 0.0008839089959106206, time: 0.0019078254699707031, model: Lasso(alpha=0.8)\n",
      "\n",
      "Ridge regression\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "7.648814198930364\n",
      "rmse: 7.284135925078364, std: 4.91968193881526, cod: 0.9453448640339259, time: 0.030031919479370117, model: Ridge(alpha=0.9)\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "0.0017219898147704527\n",
      "rmse: 0.0016566558302062457, std: 0.0011708823751943765, cod: 0.999999997172911, time: 0.09944391250610352, model: Ridge(alpha=0.9)\n",
      "Printing the 4th quartile to doublecheck std: \n",
      "39.68327998367068\n",
      "rmse: 31.141545087227655, std: 15.01484960519927, cod: 0.0010236449333226316, time: 0.0018191337585449219, model: Ridge(alpha=0.9)\n"
     ]
    }
   ],
   "source": [
    "# Regressions\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "\n",
    "\n",
    "analyse_model(LinearRegression(), x_train_pre, y_train_pre, x_test_pre, y_test_pre)\n",
    "if True:\n",
    "    # regular\n",
    "    print(\"Regular regression\")\n",
    "    print(run_model(LinearRegression(), x_train_pre, y_train_pre, x_test_pre, y_test_pre))\n",
    "    print(run_model(LinearRegression(), x_train_aug, y_train_aug, x_test_aug, y_test_aug))\n",
    "    print(run_model(LinearRegression(), x_train_pca, y_train_pca, x_test_pca, y_test_pca))\n",
    "\n",
    "    # lasso (coefficients tend to zero)\n",
    "    from sklearn.linear_model import Lasso\n",
    "    print(\"\\nLasso regression\")\n",
    "    print(run_model(Lasso(alpha=0.8), x_train_pre, y_train_pre, x_test_pre, y_test_pre))\n",
    "    print(run_model(Lasso(alpha=0.8), x_train_aug, y_train_aug, x_test_aug, y_test_aug))\n",
    "    print(run_model(Lasso(alpha=0.8), x_train_pca, y_train_pca, x_test_pca, y_test_pca))\n",
    "\n",
    "    # ridge \n",
    "    from sklearn.linear_model import Ridge\n",
    "    print(\"\\nRidge regression\")\n",
    "    print(run_model(Ridge(alpha=0.9), x_train_pre, y_train_pre, x_test_pre, y_test_pre))\n",
    "    print(run_model(Ridge(alpha=0.9), x_train_aug, y_train_aug, x_test_aug, y_test_aug))\n",
    "    print(run_model(Ridge(alpha=0.9), x_train_pca, y_train_pca, x_test_pca, y_test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d42522d5e597>:100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regular_regression = regression_model.fit(x_train.to_numpy(), y_train.to_numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the 4th quartile to doublecheck std: \n",
      "55.45619019\n",
      "rmse: 2.7067105709255226, std: 2901.6747824046297, cod: 0.9924532748299972, time: 0.2295091152191162, model: RandomForestRegressor(max_features=41, n_estimators=25, n_jobs=-1,\n",
      "                      oob_score=True, random_state=123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d42522d5e597>:100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regular_regression = regression_model.fit(x_train.to_numpy(), y_train.to_numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the 4th quartile to doublecheck std: \n",
      "55.680536119999985\n",
      "rmse: 0.5469057660220302, std: 3034.819147967697, cod: 0.9996918941809407, time: 0.7032389640808105, model: RandomForestRegressor(max_features=75, n_estimators=25, n_jobs=-1,\n",
      "                      oob_score=True, random_state=123)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d42522d5e597>:100: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regular_regression = regression_model.fit(x_train.to_numpy(), y_train.to_numpy())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the 4th quartile to doublecheck std: \n",
      "53.855534719999994\n",
      "rmse: 7.2104034294750905, std: 2578.097835133889, cod: 0.9464457396382586, time: 0.11253595352172852, model: RandomForestRegressor(max_features=5, n_estimators=25, n_jobs=-1,\n",
      "                      oob_score=True, random_state=123)\n"
     ]
    }
   ],
   "source": [
    "# Random Forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "\n",
    "# max_features is optimum at 41, but could be less to improve time and lose some score.\n",
    "rf_model_pre = RandomForestRegressor(\n",
    "            n_estimators = 25,\n",
    "            criterion    = 'mse',\n",
    "            max_depth    = None,\n",
    "            max_features = 41,\n",
    "            oob_score    = True,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 123\n",
    "         )\n",
    "# max_features is optimum at 300+ but 75 seems reasonable, yet it could be less to improve time and lose some score.\n",
    "rf_model_aug = RandomForestRegressor(\n",
    "            n_estimators = 25,\n",
    "            criterion    = 'mse',\n",
    "            max_depth    = None,\n",
    "            max_features = 75,\n",
    "            oob_score    = True,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 123\n",
    "         )\n",
    "# max_features is optimum at 5 and it cannot be higher than that. Increasing n_estimators doesn't help much.\n",
    "rf_model_pca = RandomForestRegressor(\n",
    "            n_estimators = 25,\n",
    "            criterion    = 'mse',\n",
    "            max_depth    = None,\n",
    "            max_features = 5,\n",
    "            oob_score    = True,\n",
    "            n_jobs       = -1,\n",
    "            random_state = 123\n",
    "         )\n",
    "print(run_model(rf_model_pre, x_train_pre, y_train_pre, x_test_pre, y_test_pre))\n",
    "print(run_model(rf_model_aug, x_train_aug, y_train_aug, x_test_aug, y_test_aug))\n",
    "print(run_model(rf_model_pca, x_train_pca, y_train_pca, x_test_pca, y_test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2373abfc45e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscikit_learn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "\n",
    "# single layer perceptron model in keras\n",
    "# input is the number of columns\n",
    "# there is one fully connected layer with 128 nodes, 128 is arbitrary \n",
    "# output is one float\n",
    "def make_nn1_closure(firstLayerNodes, dropOutPercentage, optimiser, activation, input_dim):\n",
    "    def make_nn1():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(firstLayerNodes, activation=activation, input_dim=input_dim))\n",
    "        model.add(Dropout(dropOutPercentage))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimiser)\n",
    "        return model\n",
    "    return make_nn1\n",
    "\n",
    "def make_nn2_closure(firstLayerNodes, secondLayerNodes, dropOutPercentage, optimiser, activation, input_dim):\n",
    "    def make_nn2():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(firstLayerNodes, activation=activation, input_dim=input_dim))\n",
    "        model.add(Dropout(dropOutPercentage))\n",
    "        model.add(Dense(secondLayerNodes, activation=activation))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        # plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "        model.compile(loss='mean_squared_error', optimizer=optimiser)\n",
    "        return model\n",
    "    return make_nn2\n",
    "\n",
    "class Params:\n",
    "        \n",
    "        def __init__(self, first_nodes, second_nodes, epochs, kfold, opti, acti, drop, batch_size):\n",
    "            self.first_nodes = first_nodes\n",
    "            self.second_nodes = second_nodes\n",
    "            self.epochs = epochs\n",
    "            self.kfold = kfold\n",
    "            self.optimizer = opti\n",
    "            self.activation = acti\n",
    "            self.drop = drop\n",
    "            self.batch_size = batch_size\n",
    "            \n",
    "        def __str__(self):\n",
    "            attrs = vars(self)\n",
    "            return ', '.join(\"%s: %s\" % item for item in attrs.items())\n",
    "\n",
    "class Grid_parameters:\n",
    "    nodeValues = list(range(5, 50))\n",
    "    batchValues = [2, 4, 8, 16, 32]\n",
    "    epochesValues = [2]#list(range(35, 75, 10))\n",
    "    kFoldSplitValues = [10, 5, 12]\n",
    "    optimizers = [\"RMSprop\", \"adam\", \"Adadelta\", \"Nadam\"]\n",
    "    activations=[\"softmax\", \"relu\", \"tanh\"]\n",
    "    dropOuts = list(np.arange(0.0, 0.8, 0.05))\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_random_params(self):\n",
    "        return Params(random.choice(self.nodeValues), \n",
    "                      random.choice(self.nodeValues),\n",
    "                      random.choice(self.epochesValues),\n",
    "                      random.choice(self.kFoldSplitValues),\n",
    "                      random.choice(self.optimizers),\n",
    "                      random.choice(self.activations),\n",
    "                      random.choice(self.dropOuts),\n",
    "                      random.choice(self.batchValues)\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating the model doesnt fit it, i.e. cannot be used to predict\n",
    "# need to regualrly fit it using all the training data\n",
    "# cv usefull for selecting the model topology\n",
    "\n",
    "# PICKLE READ FILE\n",
    "\n",
    "#infile = open('results_pre','rb')\n",
    "#new_dict = pickle.load(infile)\n",
    "#print(new_dict[0][0])\n",
    "#infile.close()\n",
    "\n",
    "grid = Grid_parameters()\n",
    "\n",
    "results_pre = []\n",
    "results_aug = []\n",
    "results_pca = []\n",
    "\n",
    "for i in range(0, 20):\n",
    "    params = grid.get_random_params()\n",
    "    print(params)\n",
    "    \n",
    "    estimators_1 = []\n",
    "    estimators_2 = []\n",
    "    estimators_1.append(('standardize', StandardScaler()))\n",
    "    estimators_2.append(('standardize', StandardScaler()))\n",
    "    \n",
    "    model_1 = make_nn1_closure(params.first_nodes, params.drop, params.optimizer, params.activation, x_train_pre.shape[1])\n",
    "    model_2 = make_nn2_closure(params.first_nodes, params.second_nodes, params.drop, params.optimizer, params.activation, x_train_pre.shape[1])\n",
    "    \n",
    "    estimators_1.append(('mlp', KerasRegressor(build_fn=model_1, \n",
    "                                             epochs=params.epochs, \n",
    "                                             batch_size=params.batch_size, \n",
    "                                             verbose=1)))\n",
    "    estimators_2.append(('mlp', KerasRegressor(build_fn=model_2, \n",
    "                                             epochs=params.epochs, \n",
    "                                             batch_size=params.batch_size, \n",
    "                                             verbose=1)))\n",
    "    \n",
    "    pipeline_1 = Pipeline(estimators_1)\n",
    "    pipeline_1 = Pipeline(estimators_2)\n",
    "    \n",
    "    kfold = KFold(n_splits=params.kfold)\n",
    "    \n",
    "    result_pre_1 = cross_val_score(pipeline_1, x_train_pre.to_numpy(), y_train_pre.to_numpy(), cv=kfold)\n",
    "    result_pre_2 = cross_val_score(pipeline_2, x_train_pre.to_numpy(), y_train_pre.to_numpy(), cv=kfold)\n",
    "    #result_aug = cross_val_score(pipeline, x_train_pre.to_numpy(), y_train_pre.to_numpy(), cv=kfold)\n",
    "    #result_pca = cross_val_score(pipeline, x_train_pre.to_numpy(), y_train_pre.to_numpy(), cv=kfold)\n",
    "    \n",
    "    print(\"Standardized: mean is %.2f, std is %.2f\" % (result_pre.mean(), result_pre.std()))\n",
    "    #print(\"Standardized: mean is %.2f, std is %.2f\" % (result_aug.mean(), result_aug.std()))\n",
    "    #print(\"Standardized: mean is %.2f, std is %.2f\" % (result_pca.mean(), result_pca.std()))\n",
    "    \n",
    "    results_pre.append((params, result_pre))\n",
    "    #results_aug.append((params, result_aug))\n",
    "    #results_pca.append((params, result_pca))\n",
    "    \n",
    "    with open('results_pre', 'wb') as save:\n",
    "        pickle.dump(results_pre, save)\n",
    "    \n",
    "    \n",
    "    \n",
    "# below I copied pased the best results \n",
    "\n",
    "# No Dropout\n",
    "# Standardized: mean is -46.98, std is 18.11\n",
    "            # running model with 29 firstLayerNodes, 8 secondLayerNodes,           \n",
    "            # 40 epochs, 10 batchSize, 10 k_fold_split\n",
    "\n",
    "# Standardized: mean is -48.66, std is 18.17\n",
    "            # running model with 29 firstLayerNodes, 44 secondLayerNodes,           \n",
    "            # 40 epochs, 5 batchSize, 5 k_fold_split\n",
    "\n",
    "# Standardized: mean is -51.15, std is 14.19, \n",
    "            # running model with 6 firstLayerNodes, 50 secondLayerNodes, \n",
    "            # 30 epochs, 20 batchSize, 10 k_fold_split\n",
    "        \n",
    "# Dropout after first dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that content_category features have high scores on average.\n",
    "# Unfortunately there are many content_categories and often \n",
    "# there is only one representative movie for each one.\n",
    "# This means that is a powerful feature but it doesnt generalize.\n",
    "# (e.g. security example: if I see a man with a gun is 100% dangerous but it's rare that such obvious feature\n",
    "# will be observed; many men are dangerous without showing a gun)\n",
    "\n",
    "categoriesWithHighWeight = [\"c_content_category_croquet ball\", \n",
    "                            \"c_content_category_bathing cap\", \n",
    "                            \"c_content_category_dumbbell\",\n",
    "                           \"c_content_category_envelope\",\n",
    "                           \"c_content_category_palace\"]\n",
    "for cat in categoriesWithHighWeight:\n",
    "    howManyRowsHaveTheCategory = sum(data[cat].tolist())\n",
    "    print(\"There are {0} raws with category {1}\".format(howManyRowsHaveTheCategory, cat))\n",
    "    categoryIndexer = (data[cat] == 1).tolist()\n",
    "    videoIdsCorrespondingToCategory = data[\"s_video_id\"][categoryIndexer]\n",
    "    boolean_array_are_some_ids_different_from_first = videoIdsCorrespondingToCategory != videoIdsCorrespondingToCategory.tolist()[0]\n",
    "    at_least_two_ids_are_different = any(boolean_array_are_some_ids_different_from_first.tolist())\n",
    "    if at_least_two_ids_are_different:\n",
    "        print(\"{0} is found on more than one movie\\n\".format(cat))\n",
    "    else :\n",
    "        print(\"{0} is found on EXACTLY one movie\\n\".format(cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now the parameters closest to 0\n",
    "epsilon = 0.1\n",
    "dfParam[((regular_regression.coef_ < epsilon) & (regular_regression.coef_ > -epsilon)).tolist()[0]].sort_values(by='Weight', ascending=False)\n",
    "\n",
    "# TODO remove e_scan_type_not supported yet? what does this column actually mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the relationship between most relevant parameters and t_average_vmaf using scatterplots\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(ncols=4)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "sns.regplot(x='c_content_category_croquet ball', y='t_average_vmaf', data=data, ax=axs[0])\n",
    "sns.regplot(x='c_colorhistogram_std_dev_medium_bright', y='t_average_vmaf', data=data, ax=axs[1])\n",
    "sns.regplot(x='c_content_category_bathing cap',y='t_average_vmaf', data=data, ax=axs[2])\n",
    "sns.regplot(x='c_colorhistogram_mean_bright',y='t_average_vmaf', data=data, ax=axs[3])\n",
    "plt.show()\n",
    "\n",
    "# Nothing useful.... I don't delete it in case we can use this tool in the future for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the correlation of the 2 most relevant (positive and negative) non-categorical variables\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "sns.regplot(x='c_colorhistogram_std_dev_medium_bright', y='c_colorhistogram_mean_bright', data=data, ax=axs[0]) #Positive\n",
    "sns.regplot(x='c_colorhistogram_std_dev_medium_dark', y='c_colorhistogram_mean_medium_bright', data=data, ax=axs[1]) #Negative\n",
    "plt.show()\n",
    "\n",
    "# Nothing useful... I don't delete it in case we can use this tool in the future for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We repeat the regular regression but we remove the content_category from the taining data\n",
    "# Purpose\n",
    "# 1: experiment and see how model performs without such scattered information\n",
    "# 2: force the model to give importance to features that generalise\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "columns_except_content_category = [col for col in x_train.columns if not 'content_category' in col]\n",
    "\n",
    "regular_regression2 = LinearRegression().fit(x_train[columns_except_content_category].to_numpy(), y_train.to_numpy())\n",
    "coefficient_of_determination2 = regular_regression2.score(x_test[columns_except_content_category].to_numpy(), y_test.to_numpy())\n",
    "print(\"Coefficient of determination on unseen test data {0}\".format(coefficient_of_determination2))\n",
    "\n",
    "predictions2 = regular_regression2.predict(x_test[columns_except_content_category].to_numpy())\n",
    "mse2 = mean_squared_error(y_test, predictions2)\n",
    "print(\"MSE on test {0}\".format(mse2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importance of predictors by purity of nodes\n",
    "# ==============================================================================\n",
    "predictors_importance = pd.DataFrame(\n",
    "                            {'predictor': data.drop(columns = \"t_average_vmaf\").columns,\n",
    "                             'importance': RFmodel.feature_importances_}\n",
    "                            )\n",
    "print(\"importance of predictors\")\n",
    "print(\"-------------------------------------------\")\n",
    "predictors_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# TODO: why is height & width so important for this model but it wasnt at all in linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance of predictors by permutation\n",
    "# ==============================================================================\n",
    "from sklearn.inspection import permutation_importance\n",
    "import multiprocessing\n",
    "\n",
    "importance = permutation_importance(\n",
    "                estimator    = RFmodel,\n",
    "                X            = x_train,\n",
    "                y            = y_train,\n",
    "                n_repeats    = 5,\n",
    "                scoring      = 'neg_root_mean_squared_error',\n",
    "                n_jobs       = multiprocessing.cpu_count() - 1,\n",
    "                random_state = 123\n",
    "             )\n",
    "\n",
    "# Store results (mean and stddev) in a dataframe\n",
    "df_importance = pd.DataFrame(\n",
    "                    {k: importance[k] for k in ['importances_mean', 'importances_std']}\n",
    "                 )\n",
    "df_importance['feature'] = x_train.columns\n",
    "df_importance.sort_values('importances_mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "# we can see how the content_categories feature have very little importance.\n",
    "# This is expected since creating a 'split' on a feture that is valorised only for\n",
    "# a small number of datapoints is against the criteria of how random forest works\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 18))\n",
    "df_importance = df_importance.sort_values('importances_mean', ascending=True)\n",
    "ax.barh(\n",
    "    df_importance['feature'],\n",
    "    df_importance['importances_mean'],\n",
    "    xerr=df_importance['importances_std'],\n",
    "    align='center',\n",
    "    alpha=0\n",
    ")\n",
    "ax.plot(\n",
    "    df_importance['importances_mean'],\n",
    "    df_importance['feature'],\n",
    "    marker=\"D\",\n",
    "    linestyle=\"\",\n",
    "    alpha=0.8,\n",
    "    color=\"r\"\n",
    ")\n",
    "ax.set_title('Importance of predictors (train)')\n",
    "ax.set_xlabel('Error increase after permutation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max score: 0.9440248985901017\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x276.48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1 == 0:  # Skip it, this cell is used only to obtain the optimum value of n_estimators through out-of-bag error\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Validation using Out-of-Bag error\n",
    "    # ==============================================================================\n",
    "    train_scores = []\n",
    "    oob_scores   = []\n",
    "    iter_x_train = x_train_pca\n",
    "    iter_y_train = y_train_pca\n",
    "\n",
    "    # Evaluated values\n",
    "    estimator_range = range(1, 50, 2)\n",
    "\n",
    "    # Loop to train model with each n_estimators value and obtain its training and OOB error\n",
    "    for n_estimators in estimator_range:\n",
    "        RFmodel = RandomForestRegressor(\n",
    "                    n_estimators = n_estimators,\n",
    "                    criterion    = 'mse',\n",
    "                    max_depth    = None,\n",
    "                    max_features = 'auto',\n",
    "                    oob_score    = True,\n",
    "                    n_jobs       = -1,\n",
    "                    random_state = 123\n",
    "                 )\n",
    "        RFmodel.fit(iter_x_train, iter_y_train)\n",
    "        train_scores.append(RFmodel.score(iter_x_train, iter_y_train))\n",
    "        oob_scores.append(RFmodel.oob_score_)\n",
    "\n",
    "    # Graph with the error trend\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "    ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "    ax.plot(estimator_range, oob_scores, label=\"out-of-bag scores\")\n",
    "    ax.plot(estimator_range[np.argmax(oob_scores)], max(oob_scores),\n",
    "            marker='o', color = \"red\", label=\"max score\")\n",
    "    ax.set_ylabel(\"R^2\")\n",
    "    ax.set_xlabel(\"n_estimators\")\n",
    "    ax.set_title(\"out-of-bag-error evolution vs number of trees\")\n",
    "    plt.legend();\n",
    "    print(f\"Max score: {max(oob_scores)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x276.48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 0 == 1:  # Skip it, this cell is used only to obtain the optimum value of n_estimators through k-cross-validation and neg_root_mean_squared_error\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    # Validation using k-cross-validation and neg_root_mean_squared_error\n",
    "    # ==============================================================================\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    train_scores = []\n",
    "    cv_scores    = []\n",
    "    iter_x_train = x_train_pca\n",
    "    iter_y_train = y_train_pca\n",
    "\n",
    "    # Evaluated values\n",
    "    estimator_range = range(1, 30, 2)\n",
    "\n",
    "    # Loop to train a model with each n_estimators value and obtain its training and\n",
    "    # k-cross-validation error.\n",
    "    for n_estimators in estimator_range:\n",
    "\n",
    "        RFmodel = RandomForestRegressor(\n",
    "                    n_estimators = n_estimators,\n",
    "                    criterion    = 'mse',\n",
    "                    max_depth    = None,\n",
    "                    max_features = 'auto',\n",
    "                    oob_score    = False,\n",
    "                    n_jobs       = -1,\n",
    "                    random_state = 123\n",
    "                 )\n",
    "\n",
    "        # Train error\n",
    "        RFmodel.fit(iter_x_train, iter_y_train)\n",
    "        RFpredictions = RFmodel.predict(X = iter_x_train)\n",
    "        rmse = mean_squared_error(\n",
    "                y_true  = iter_y_train,\n",
    "                y_pred  = RFpredictions,\n",
    "                squared = False\n",
    "               )\n",
    "        train_scores.append(rmse)\n",
    "\n",
    "        # Cross validation error\n",
    "        RFscores = cross_val_score(\n",
    "                    estimator = RFmodel,\n",
    "                    X         = iter_x_train,\n",
    "                    y         = iter_y_train,\n",
    "                    scoring   = 'neg_root_mean_squared_error',\n",
    "                    cv        = 5\n",
    "                 )\n",
    "        # Se agregan los scores de cross_val_score() y se pasa a positivo\n",
    "        cv_scores.append(-1*RFscores.mean())\n",
    "\n",
    "    # Graph with the error trend\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "    ax.plot(estimator_range, train_scores, label=\"train scores\")\n",
    "    ax.plot(estimator_range, cv_scores, label=\"cv scores\")\n",
    "    ax.plot(estimator_range[np.argmin(cv_scores)], min(cv_scores),\n",
    "            marker='o', color = \"red\", label=\"min score\")\n",
    "    ax.set_ylabel(\"root_mean_squared_error\")\n",
    "    ax.set_xlabel(\"n_estimators\")\n",
    "    ax.set_title(\"cv-error evolution vs tree number\")\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimum value of max_features: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x276.48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 1 == 0:  # Skip it, this cell is used only to obtain the optimum value of max_features through Out-of-Bag error\n",
    "    \n",
    "    # Validation using Out-of-Bag error\n",
    "    # ==============================================================================\n",
    "    import math\n",
    "\n",
    "    train_scores = []\n",
    "    oob_scores   = []\n",
    "    iter_x_train = x_train_pca\n",
    "    iter_y_train = y_train_pca\n",
    "\n",
    "    # Evaluated values\n",
    "    max_features_range = range(1, 2*math.ceil(iter_x_train.shape[1]/2), 1)\n",
    "\n",
    "    # Loop to train a model with each max_features value and obtain its training and\n",
    "    # Out-of-Bag error.\n",
    "    for max_features in max_features_range:\n",
    "        RFmodel = RandomForestRegressor(\n",
    "                    n_estimators = 25,\n",
    "                    criterion    = 'mse',\n",
    "                    max_depth    = None,\n",
    "                    max_features = max_features,\n",
    "                    oob_score    = True,\n",
    "                    n_jobs       = -1,\n",
    "                    random_state = 123\n",
    "                 )\n",
    "        RFmodel.fit(iter_x_train, iter_y_train)\n",
    "        train_scores.append(RFmodel.score(iter_x_train, iter_y_train))\n",
    "        oob_scores.append(RFmodel.oob_score_)\n",
    "\n",
    "    # Graph with the error trend\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "    ax.plot(max_features_range, train_scores, label=\"train scores\")\n",
    "    ax.plot(max_features_range, oob_scores, label=\"out-of-bag scores\")\n",
    "    ax.plot(max_features_range[np.argmax(oob_scores)], max(oob_scores),\n",
    "            marker='o', color = \"red\")\n",
    "    ax.set_ylabel(\"R^2\")\n",
    "    ax.set_xlabel(\"max_features\")\n",
    "    ax.set_title(\"out-of-bag-error evolution vs number of predictors\")\n",
    "    plt.legend();\n",
    "    print(f\"optimum value of max_features: {max_features_range[np.argmax(oob_scores)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_determination(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred ))\n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) )\n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
